from __future__ import annotations

import json
import os
import shutil
import uuid
from importlib import metadata
from datetime import datetime, timedelta, timezone
from html import escape
from typing import Any, Dict, List, Optional
from urllib.parse import quote

from . import db
from .receipts import config_hash as config_hash_fn
from .utils import format_ts, get_git_commit, parse_ts


STYLE = """
body { font-family: Georgia, "Times New Roman", serif; margin: 2rem; color: #111; }
header { margin-bottom: 2rem; }
h1, h2, h3 { font-family: "Gill Sans", "Trebuchet MS", sans-serif; }
table { border-collapse: collapse; width: 100%; margin: 1rem 0; }
th, td { border-bottom: 1px solid #ddd; padding: 0.5rem; text-align: left; }
.small { color: #666; font-size: 0.9rem; }
.grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(220px, 1fr)); gap: 1rem; }
.card { border: 1px solid #ddd; padding: 1rem; border-radius: 6px; }
a { color: #0b5394; text-decoration: none; }
a:hover { text-decoration: underline; }
code { font-family: "Courier New", monospace; }
.badge { display: inline-block; padding: 0.15rem 0.5rem; border-radius: 3px; font-size: 0.8rem; font-weight: bold; margin-right: 0.3rem; }
.badge-stable { background: #d4edda; color: #155724; }
.badge-burst { background: #fff3cd; color: #856404; }
.badge-churn { background: #f8d7da; color: #721c24; }
.badge-fixated { background: #ffe0cc; color: #7a3300; }
.badge-flipflop { background: #e2d5f1; color: #3d1f6e; }
.health-bar { display: flex; gap: 1.5rem; align-items: center; margin: 0.5rem 0; }
.health-metric { text-align: center; }
.health-metric .value { font-size: 1.4rem; font-weight: bold; }
.health-metric .label { font-size: 0.75rem; color: #666; }
.sparkline { vertical-align: middle; }
.anomaly-row { background: #fff8f0; }
.methods { background: #f8f9fa; border: 1px solid #e9ecef; padding: 1rem; border-radius: 6px; margin-top: 2rem; font-size: 0.85rem; }
"""


def _write(path: str, content: str) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def _write_json(path: str, payload: Any) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2, sort_keys=True)


def _layout(title: str, body: str) -> str:
    return f"""<!doctype html>
<html lang=\"en\">
<head>
<meta charset=\"utf-8\" />
<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />
<title>{escape(title)}</title>
<style>{STYLE}</style>
</head>
<body>
<header>
<h1>{escape(title)}</h1>
<p class=\"small\">Generated by labelwatch</p>
</header>
{body}
</body>
</html>"""


def _table(headers: List[str], rows: List[List[str]]) -> str:
    head = "".join(f"<th>{escape(h)}</th>" for h in headers)
    body = "".join("<tr>" + "".join(f"<td>{cell}</td>" for cell in row) + "</tr>" for row in rows)
    return f"<table><thead><tr>{head}</tr></thead><tbody>{body}</tbody></table>"


def _sparkline_svg(values: List[int], width: int = 120, height: int = 24) -> str:
    """Render an inline SVG sparkline from a list of values."""
    if not values or max(values) == 0:
        return f'<svg class="sparkline" width="{width}" height="{height}"></svg>'
    n = len(values)
    peak = max(values)
    pad = 1
    points = []
    for i, v in enumerate(values):
        x = pad + (i / max(n - 1, 1)) * (width - 2 * pad)
        y = height - pad - (v / peak) * (height - 2 * pad)
        points.append(f"{x:.1f},{y:.1f}")
    polyline = " ".join(points)
    return (
        f'<svg class="sparkline" width="{width}" height="{height}" viewBox="0 0 {width} {height}">'
        f'<polyline points="{polyline}" fill="none" stroke="#0b5394" stroke-width="1.5" />'
        f'</svg>'
    )


def _hourly_counts(conn, labeler_did: str, start: str, end: str, buckets: int = 168) -> List[int]:
    """Return hourly event counts for a labeler over a time range."""
    rows = conn.execute(
        "SELECT ts FROM label_events WHERE labeler_did=? AND ts>=? AND ts<? ORDER BY ts",
        (labeler_did, start, end),
    ).fetchall()
    if not rows:
        return [0] * buckets
    start_dt = parse_ts(start)
    if start_dt.tzinfo is None:
        start_dt = start_dt.replace(tzinfo=timezone.utc)
    counts = [0] * buckets
    for r in rows:
        dt = _parse_ts_safe(r["ts"])
        if dt is None:
            continue
        offset_hours = int((dt - start_dt).total_seconds() / 3600)
        idx = max(0, min(buckets - 1, offset_hours))
        counts[idx] += 1
    return counts


def _labeler_badges(conn, labeler_did: str, start: str, end: str) -> List[tuple[str, str]]:
    """Return (label, css_class) badge tuples for a labeler based on alerts."""
    alert_rows = conn.execute(
        "SELECT rule_id FROM alerts WHERE labeler_did=? AND ts>=? AND ts<=?",
        (labeler_did, start, end),
    ).fetchall()
    rules_fired = {r["rule_id"] for r in alert_rows}
    badges = []
    if "label_rate_spike" in rules_fired:
        badges.append(("Burst-prone", "badge-burst"))
    if "churn_index" in rules_fired:
        badges.append(("High churn", "badge-churn"))
    if "target_concentration" in rules_fired:
        badges.append(("Target-fixated", "badge-fixated"))
    if "flip_flop" in rules_fired:
        badges.append(("Reversal-heavy", "badge-flipflop"))
    if not badges:
        badges.append(("Stable", "badge-stable"))
    return badges


def _badges_html(badges: List[tuple[str, str]]) -> str:
    return " ".join(f'<span class="badge {cls}">{escape(label)}</span>' for label, cls in badges)


def _labeler_health_card(conn, labeler_did: str, start_7d: str, now_ts: str, sparkline_counts: List[int]) -> str:
    """Render a health card with key metrics and sparkline for a labeler."""
    events_7d = conn.execute(
        "SELECT COUNT(*) AS c FROM label_events WHERE labeler_did=? AND ts>=? AND ts<=?",
        (labeler_did, start_7d, now_ts),
    ).fetchone()["c"]
    unique_targets = conn.execute(
        "SELECT COUNT(DISTINCT uri) AS c FROM label_events WHERE labeler_did=? AND ts>=? AND ts<=?",
        (labeler_did, start_7d, now_ts),
    ).fetchone()["c"]
    alert_count = conn.execute(
        "SELECT COUNT(*) AS c FROM alerts WHERE labeler_did=? AND ts>=? AND ts<=?",
        (labeler_did, start_7d, now_ts),
    ).fetchone()["c"]
    target_spread = f"{unique_targets}/{events_7d}" if events_7d else "0/0"
    sparkline = _sparkline_svg(sparkline_counts)
    badges = _labeler_badges(conn, labeler_did, start_7d, now_ts)

    return f"""
<div class="card">
  <div class="health-bar">
    <div class="health-metric"><div class="value">{events_7d}</div><div class="label">Events (7d)</div></div>
    <div class="health-metric"><div class="value">{target_spread}</div><div class="label">Targets/Events</div></div>
    <div class="health-metric"><div class="value">{alert_count}</div><div class="label">Anomalies</div></div>
    <div class="health-metric">{sparkline}<div class="label">Activity (7d)</div></div>
  </div>
  <div>{_badges_html(badges)}</div>
</div>
"""


METHODS_HTML = """
<div class="methods">
<h3>Methods and caveats</h3>
<ul>
<li>Behavioral telemetry only. No intent claims, no content judgments, no verdicts.</li>
<li>Rules detect geometric patterns (rate anomalies, target distribution, churn). Thresholds are configurable.</li>
<li>Every alert includes a receipted hash over rule_id, config, inputs, and evidence for reproducibility.</li>
<li>Sparklines show hourly event counts over 7 days. Badges summarize which rules fired in the period.</li>
<li>Observation surface: label events from com.atproto.label.queryLabels. Does not observe content, profiles, or social graph.</li>
</ul>
</div>
"""


def _alerts_by_rule(conn, start: str, end: str) -> Dict[str, int]:
    rows = conn.execute(
        "SELECT rule_id, COUNT(*) AS c FROM alerts WHERE ts>=? AND ts<=? GROUP BY rule_id",
        (start, end),
    ).fetchall()
    return {r["rule_id"]: r["c"] for r in rows}


def _top_labelers(conn, start: str, end: str, limit: int = 10) -> List[Dict[str, Any]]:
    rows = conn.execute(
        """
        SELECT labeler_did, COUNT(*) AS c
        FROM alerts
        WHERE ts>=? AND ts<=?
        GROUP BY labeler_did
        ORDER BY c DESC
        LIMIT ?
        """,
        (start, end, limit),
    ).fetchall()
    return [{"labeler_did": r["labeler_did"], "count": r["c"]} for r in rows]


def _labeler_activity(conn, labeler_did: str, start: str, end: str) -> int:
    return conn.execute(
        "SELECT COUNT(*) AS c FROM label_events WHERE labeler_did=? AND ts>=? AND ts<=?",
        (labeler_did, start, end),
    ).fetchone()["c"]


def _top_targets(conn, labeler_did: str, start: str, end: str, limit: int = 10) -> List[Dict[str, Any]]:
    rows = conn.execute(
        """
        SELECT uri, COUNT(*) AS c
        FROM label_events
        WHERE labeler_did=? AND ts>=? AND ts<=?
        GROUP BY uri
        ORDER BY c DESC
        LIMIT ?
        """,
        (labeler_did, start, end, limit),
    ).fetchall()
    return [{"uri": r["uri"], "count": r["c"]} for r in rows]


def _alert_events(conn, evidence_hashes: List[str]) -> List[Dict[str, Any]]:
    if not evidence_hashes:
        return []
    placeholders = ",".join(["?"] * len(evidence_hashes))
    rows = conn.execute(
        f"SELECT id, ts, uri, val, neg, cid, event_hash FROM label_events WHERE event_hash IN ({placeholders})",
        evidence_hashes,
    ).fetchall()
    return [dict(r) for r in rows]


def _count_naive_timestamps(conn, table: str) -> int:
    row = conn.execute(
        f"""
        SELECT SUM(
            CASE
                WHEN substr(ts, -1) = 'Z' THEN 0
                WHEN (substr(ts, -6, 1) IN ('+', '-') AND substr(ts, -3, 1) = ':') THEN 0
                ELSE 1
            END
        ) AS c
        FROM {table}
        """
    ).fetchone()
    return int(row["c"] or 0)


def _max_ts(conn, table: str) -> Optional[str]:
    row = conn.execute(f"SELECT MAX(ts) AS ts FROM {table}").fetchone()
    return row["ts"] if row and row["ts"] else None


def _parse_ts_safe(value: Optional[str]) -> Optional[datetime]:
    if not value:
        return None
    dt = parse_ts(value)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return dt


def _get_package_version() -> Optional[str]:
    try:
        return metadata.version("labelwatch")
    except metadata.PackageNotFoundError:
        return None


def _prepare_out_dir(out_dir: str) -> str:
    parent = os.path.dirname(os.path.abspath(out_dir)) or "."
    os.makedirs(parent, exist_ok=True)
    tmp_dir = os.path.join(parent, f".report-tmp-{uuid.uuid4().hex}")
    os.makedirs(tmp_dir, exist_ok=True)
    return tmp_dir


def _commit_out_dir(tmp_dir: str, out_dir: str) -> None:
    if os.path.exists(out_dir):
        backup = out_dir + ".prev"
        if os.path.exists(backup):
            shutil.rmtree(backup)
        os.replace(out_dir, backup)
    os.replace(tmp_dir, out_dir)


def generate_report(conn, out_dir: str, now: Optional[datetime] = None) -> None:
    real_now = datetime.now(timezone.utc)
    if now is None:
        now = real_now
    if now.tzinfo is None:
        now = now.replace(tzinfo=timezone.utc)
    now = now.astimezone(timezone.utc)
    clamped = False
    if now > real_now:
        now = real_now
        clamped = True
    now_ts = format_ts(now)

    last_ingest = _max_ts(conn, "label_events")
    last_scan = _max_ts(conn, "alerts")

    max_label = _parse_ts_safe(last_ingest)
    max_alert = _parse_ts_safe(last_scan)
    max_raw_dt = None
    if max_label and max_alert:
        max_raw_dt = max(max_label, max_alert)
    else:
        max_raw_dt = max_label or max_alert
    max_raw_ts = format_ts(max_raw_dt) if max_raw_dt else None
    skew_seconds = 0
    if max_raw_dt:
        skew_seconds = max(0, int((max_raw_dt - real_now).total_seconds()))

    naive_count = _count_naive_timestamps(conn, "label_events") + _count_naive_timestamps(conn, "alerts")
    timestamps_assumed_utc = naive_count > 0

    cfg_hash_latest = None
    cfg_row = conn.execute("SELECT config_hash FROM alerts ORDER BY ts DESC LIMIT 1").fetchone()
    if cfg_row:
        cfg_hash_latest = cfg_row["config_hash"]
    if cfg_hash_latest is None:
        cfg_hash_latest = config_hash_fn({"rules": ["label_rate_spike", "flip_flop"]})

    build_signature = {
        "package_version": _get_package_version(),
        "schema_version": db.SCHEMA_VERSION,
        "git_commit": get_git_commit(),
        "config_hash": cfg_hash_latest,
    }

    schema_version_source = "db" if db.get_schema_version(conn) is not None else "code"

    start_24h = format_ts(now - timedelta(hours=24))
    start_7d = format_ts(now - timedelta(days=7))

    alerts_24h = _alerts_by_rule(conn, start_24h, now_ts)
    alerts_7d = _alerts_by_rule(conn, start_7d, now_ts)
    top_labelers = _top_labelers(conn, start_7d, now_ts)

    labelers = conn.execute("SELECT * FROM labelers ORDER BY labeler_did").fetchall()
    alerts = conn.execute("SELECT * FROM alerts ORDER BY ts DESC").fetchall()

    overview = {
        "generated_at": now_ts,
        "last_ingest": last_ingest,
        "last_scan": last_scan,
        "schema_version": db.SCHEMA_VERSION,
        "schema_version_source": schema_version_source,
        "alerts_by_rule_24h": alerts_24h,
        "alerts_by_rule_7d": alerts_7d,
        "top_labelers_7d": top_labelers,
        "labeler_count": len(labelers),
        "alert_count": len(alerts),
        "now_clamped_to_real_time": clamped,
        "max_raw_timestamp_seen": max_raw_ts,
        "max_skew_seconds": skew_seconds,
        "timestamps_assumed_utc": timestamps_assumed_utc,
        "naive_timestamp_count": naive_count,
        "build_signature": build_signature,
    }

    tmp_dir = _prepare_out_dir(out_dir)
    _write_json(os.path.join(tmp_dir, "overview.json"), overview)

    labeler_rows = []
    for row in labelers:
        did = row["labeler_did"]
        did_path = quote(did, safe="")
        labeler_rows.append({
            "labeler_did": did,
            "first_seen": row["first_seen"],
            "last_seen": row["last_seen"],
            "href": f"labeler/{did_path}.html",
        })
    _write_json(os.path.join(tmp_dir, "labelers.json"), labeler_rows)

    alert_rows = []
    for row in alerts:
        alert_rows.append({
            "id": row["id"],
            "rule_id": row["rule_id"],
            "labeler_did": row["labeler_did"],
            "ts": row["ts"],
            "href": f"alert/{row['id']}.html",
        })
    _write_json(os.path.join(tmp_dir, "alerts.json"), alert_rows)

    skew_note = ""
    if skew_seconds > 0:
        skew_note = f"<div class=\"card\"><h3>Clock skew</h3><div>{skew_seconds}s</div></div>"
    overview_cards = f"""
<div class=\"grid\">
  <div class=\"card\"><h3>Generated</h3><div>{escape(now_ts)}</div></div>
  <div class=\"card\"><h3>Last ingest</h3><div>{escape(str(last_ingest))}</div></div>
  <div class=\"card\"><h3>Last scan</h3><div>{escape(str(last_scan))}</div></div>
  <div class=\"card\"><h3>Labelers</h3><div>{len(labelers)}</div></div>
  <div class=\"card\"><h3>Alerts</h3><div>{len(alerts)}</div></div>
  {skew_note}
</div>
"""

    def dict_rows(d: Dict[str, int]) -> List[List[str]]:
        return [[escape(k), str(v)] for k, v in sorted(d.items(), key=lambda x: x[0])]

    overview_tables = ""
    if alerts_24h:
        overview_tables += "<h2>Alerts by rule (24h)</h2>" + _table(["rule_id", "count"], dict_rows(alerts_24h))
    if alerts_7d:
        overview_tables += "<h2>Alerts by rule (7d)</h2>" + _table(["rule_id", "count"], dict_rows(alerts_7d))

    top_rows = [[f"<a href=\"labeler/{quote(r['labeler_did'], safe='')}.html\">{escape(r['labeler_did'])}</a>", str(r["count"]) ] for r in top_labelers]
    if top_rows:
        overview_tables += "<h2>Top labelers by alerts (7d)</h2>" + _table(["labeler", "count"], top_rows)

    build_rows = [
        ["package_version", escape(str(build_signature["package_version"]))],
        ["schema_version", escape(str(build_signature["schema_version"]))],
        ["git_commit", escape(str(build_signature["git_commit"]))],
        ["config_hash", f"<code>{escape(str(build_signature['config_hash']))}</code>"],
    ]
    build_table = "<h2>Build signature</h2>" + _table(["field", "value"], build_rows)

    labeler_table_rows = []
    for r in labelers:
        did = r["labeler_did"]
        badges = _labeler_badges(conn, did, start_7d, now_ts)
        counts = _hourly_counts(conn, did, start_7d, now_ts)
        spark = _sparkline_svg(counts)
        labeler_table_rows.append([
            f"<a href=\"labeler/{quote(did, safe='')}.html\">{escape(did)}</a>",
            escape(str(r["first_seen"])),
            escape(str(r["last_seen"])),
            spark,
            _badges_html(badges),
        ])
    labeler_links = "<h2>Labelers</h2>" + _table(
        ["labeler_did", "first_seen", "last_seen", "activity", "behavior"],
        labeler_table_rows,
    )

    anomaly_rules = {"label_rate_spike", "flip_flop", "target_concentration", "churn_index"}
    alert_table_rows = []
    for r in alerts[:50]:
        is_anomaly = r["rule_id"] in anomaly_rules
        row_class = ' class="anomaly-row"' if is_anomaly else ""
        alert_table_rows.append(
            f"<tr{row_class}>"
            f"<td><a href=\"alert/{r['id']}.html\">{r['id']}</a></td>"
            f"<td>{escape(r['rule_id'])}</td>"
            f"<td>{escape(r['labeler_did'])}</td>"
            f"<td>{escape(r['ts'])}</td>"
            f"</tr>"
        )
    alert_head = "<tr><th>id</th><th>rule_id</th><th>labeler</th><th>ts</th></tr>"
    alert_links = f"<h2>Recent alerts</h2><table><thead>{alert_head}</thead><tbody>{''.join(alert_table_rows)}</tbody></table>"

    naive_banner = ""
    if naive_count > 0:
        naive_banner = f"<p class=\"small\">Note: {naive_count} timestamps lacked timezone info and were assumed UTC.</p>"
    overview_html = _layout("Labelwatch overview", overview_cards + naive_banner + build_table + overview_tables + labeler_links + alert_links + METHODS_HTML)
    _write(os.path.join(tmp_dir, "index.html"), overview_html)

    for row in labelers:
        did = row["labeler_did"]
        did_path = quote(did, safe="")
        alerts_rows = conn.execute(
            "SELECT * FROM alerts WHERE labeler_did=? ORDER BY ts DESC",
            (did,),
        ).fetchall()
        events_24h = _labeler_activity(conn, did, start_24h, now_ts)
        events_7d = _labeler_activity(conn, did, start_7d, now_ts)
        top_targets = _top_targets(conn, did, start_7d, now_ts)

        payload = {
            "labeler_did": did,
            "first_seen": row["first_seen"],
            "last_seen": row["last_seen"],
            "events_24h": events_24h,
            "events_7d": events_7d,
            "alerts": [dict(r) for r in alerts_rows],
            "top_targets_7d": top_targets,
        }
        _write_json(os.path.join(tmp_dir, "labeler", f"{did_path}.json"), payload)

        sparkline_counts = _hourly_counts(conn, did, start_7d, now_ts)
        health_card = _labeler_health_card(conn, did, start_7d, now_ts, sparkline_counts)

        info_card = f"""
<div class=\"grid\">
  <div class=\"card\"><h3>Labeler</h3><div><code>{escape(did)}</code></div></div>
  <div class=\"card\"><h3>First seen</h3><div>{escape(str(row['first_seen']))}</div></div>
  <div class=\"card\"><h3>Last seen</h3><div>{escape(str(row['last_seen']))}</div></div>
  <div class=\"card\"><h3>Events (24h)</h3><div>{events_24h}</div></div>
  <div class=\"card\"><h3>Events (7d)</h3><div>{events_7d}</div></div>
  <div class=\"card\"><h3>Alerts</h3><div>{len(alerts_rows)}</div></div>
</div>
"""
        targets_table = ""
        if top_targets:
            targets_table = "<h2>Top targets (7d)</h2>" + _table(
                ["uri", "count"],
                [[escape(t["uri"]), str(t["count"])] for t in top_targets],
            )
        alert_detail_rows = []
        for r in alerts_rows:
            is_anomaly = r["rule_id"] in anomaly_rules
            row_class = ' class="anomaly-row"' if is_anomaly else ""
            alert_detail_rows.append(
                f"<tr{row_class}>"
                f"<td><a href=\"../alert/{r['id']}.html\">{r['id']}</a></td>"
                f"<td>{escape(r['rule_id'])}</td>"
                f"<td>{escape(r['ts'])}</td>"
                f"</tr>"
            )
        alert_head = "<tr><th>id</th><th>rule_id</th><th>ts</th></tr>"
        alerts_table = f"<h2>Alerts timeline</h2><table><thead>{alert_head}</thead><tbody>{''.join(alert_detail_rows)}</tbody></table>"
        html = _layout(f"Labeler {did}", f"<p><a href=\"../index.html\">Overview</a></p>" + health_card + info_card + targets_table + alerts_table + METHODS_HTML)
        _write(os.path.join(tmp_dir, "labeler", f"{did_path}.html"), html)

    for row in alerts:
        evidence_hashes = json.loads(row["evidence_hashes_json"])
        events = _alert_events(conn, evidence_hashes)
        payload = {
            "alert": dict(row),
            "evidence_events": events,
        }
        _write_json(os.path.join(tmp_dir, "alert", f"{row['id']}.json"), payload)

        receipt_table = _table(
            ["field", "value"],
            [["rule_id", escape(row["rule_id"])],
             ["labeler_did", escape(row["labeler_did"])],
             ["ts", escape(row["ts"])],
             ["config_hash", f"<code>{escape(row['config_hash'])}</code>"],
             ["receipt_hash", f"<code>{escape(row['receipt_hash'])}</code>"],
             ["inputs", f"<pre>{escape(row['inputs_json'])}</pre>"],
             ["evidence_hashes", f"<pre>{escape(row['evidence_hashes_json'])}</pre>"],
            ],
        )
        events_table = "<p>No evidence events recorded.</p>"
        if events:
            events_table = _table(
                ["id", "ts", "uri", "val", "neg", "cid", "event_hash"],
                [[str(e["id"]), escape(e["ts"]), escape(e["uri"]), escape(e["val"]), str(e["neg"]), escape(str(e["cid"])), f"<code>{escape(e['event_hash'])}</code>"] for e in events],
            )
        html = _layout(
            f"Alert {row['id']}",
            f"<p><a href=\"../index.html\">Overview</a></p>" + receipt_table + "<h2>Evidence events</h2>" + events_table,
        )
        _write(os.path.join(tmp_dir, "alert", f"{row['id']}.html"), html)

    _commit_out_dir(tmp_dir, out_dir)
